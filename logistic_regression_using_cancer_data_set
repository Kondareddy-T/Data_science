# -*- coding: utf-8 -*-
"""
Spyder Editor

This is a temporary script file.
"""
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd 
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix


dataset = pd.read_csv(r'C:\cancer.csv')
x=dataset.iloc[:,2:].values
y=dataset.iloc[:,1].values
#pd.set_option("display.max_rows", None, "display.max_columns", None) This is to get maximum colums and rows to get displayed.
#print(dataset.head(5)) to display 5 rows of all columns
print('the size of the dataset is {}'.format(dataset.shape))
print(dataset['diagnosis'].value_counts())
# print((dataset['diagnosis']=='M').sum()) To count no.of 'M's using Trues and falses
#print(dataset.isna().sum()) Prints no.of Nan values in each column
#print(dataset.isnull().sum()) #This is same as above

labelencoder_y=LabelEncoder()
y=labelencoder_y.fit_transform(y)
#print(y)

# Splitting the dataset into the Training set and Test set
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, random_state = 0)

#Feature Scaling
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.fit_transform(x_test)

#Using Logistic Regression Algorithm to the Training Set
classifier = LogisticRegression(random_state=0)
classifier.fit(x_train,y_train)

#predict the test set results
y_predict = classifier.predict(x_test)

#confusion matrix to find the number of wrong predictions
cm = confusion_matrix(y_test, y_predict)
a=cm[0,0] + cm[1,1]
b=len(y_test)
accuracy = (a/b)*100
print(accuracy)



